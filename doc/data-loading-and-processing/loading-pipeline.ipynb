{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data loading"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import re\n",
    "import magic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import concurrent.futures\n",
    "import datetime\n",
    "import pytesseract\n",
    "import pdf2image\n",
    "\n",
    "# gs\n",
    "gs_url = \"https://github.com/ArtifexSoftware/ghostpdl-downloads/releases/download/gs9540/ghostscript-9.54.0-linux-x86_64.tgz\"\n",
    "r = requests.get(gs_url, allow_redirects=True)\n",
    "open(\"gs.tgz\", \"wb\").write(r.content)\n",
    "os.system(\"tar -xzvf gs.tgz\")\n",
    "os.remove(\"gs.tgz\")\n",
    "shutil.move(\"ghostscript-9.54.0-linux-x86_64/gs-9540-linux-x86_64\",\"gs\")\n",
    "shutil.rmtree(\"ghostscript-9.54.0-linux-x86_64\", ignore_errors=True)\n",
    "\n",
    "# tes language model\n",
    "tes_url = \"https://github.com/tesseract-ocr/tessdata/raw/master/eng.traineddata\"\n",
    "r = requests.get(tes_url, allow_redirects=True)\n",
    "open(\"eng.traineddata\", \"wb\").write(r.content)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "23466654"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "docs = pd.read_excel(\"../../data/un-global-impact.xlsx\", sheet_name=[0,1])\n",
    "docs = pd.concat([v.loc[:,\"Participant\":\"Link\"] for k,v in docs.items()])\n",
    "# get only the eng ones with a link\n",
    "docs = docs[(docs.Language==\"english\") & (docs.Link.notnull())].\\\n",
    "    sort_values([\"Year\", \"Participant\", \"Link\"]).drop_duplicates(\"Link\").\\\n",
    "        reset_index(drop=True)\n",
    "#docs = docs.loc[[74,75,76,77,78,79,80,81,82,151,544,568,810,863],:].reset_index(drop=True)\n",
    "#docs = docs.loc[range(0,10),:].reset_index(drop=True)\n",
    "\n",
    "# file types\n",
    "file_type = docs.Link.str.split(\"/\").apply(lambda x: x[-1].split(\"?\")[0].split(\".\")[-1]).str.lower()\n",
    "docs[\"FileType\"] = [\"\" if f not in set([\"pdf\", \"docx\", \"pptx\", \"doc\", \"docm\", \"htm\", \"html\"]) else f\\\n",
    "    for f in file_type.values]\n",
    "# prepare file names\n",
    "def sanitize_names(r):\n",
    "    ind = str(r.name).rjust(4,\"0\")\n",
    "    year = str(r.Year)\n",
    "    part = r.Participant\n",
    "    part = part.lower()\n",
    "    part = re.sub(\"[.!?\\\\-/,\\\"\\(\\)\\+'\\|]\",\" \",part)\n",
    "    part = re.sub(\"&\",\" and \",part)\n",
    "    part = re.sub(\" +\",\"-\",part)\n",
    "    part = re.sub(\"-$\",\"\",part)\n",
    "    pp = [ind, year, part]\n",
    "    res = \"-\".join(pp)\n",
    "    if len(r.FileType)>0:\n",
    "        res = res+\".\"+r.FileType\n",
    "    return res\n",
    "docs[\"FileName\"] = docs.apply(sanitize_names, axis=1)\n",
    "\n",
    "docs.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                       Participant                          Sector  Country  \\\n",
       "0                      AGNI MOTORS  Electronic & Electrical Equ...    India   \n",
       "1                        AMBEV S/A                       Beverages   Brazil   \n",
       "2  Access Spectrum Company Limited  Technology Hardware & Equip...  Myanmar   \n",
       "3                 Addit Sp. z o.o.             General Industrials   Poland   \n",
       "4                       Ahlsell AB  Technology Hardware & Equip...   Sweden   \n",
       "\n",
       "   Year Language                                               Link FileType  \\\n",
       "0  2019  english  https://ungc-production.s3.us-west-2.amazonaws...      pdf   \n",
       "1  2019  english  https://ungc-production.s3.us-west-2.amazonaws...      pdf   \n",
       "2  2019  english  https://ungc-production.s3.us-west-2.amazonaws...      pdf   \n",
       "3  2019  english  https://ungc-production.s3.us-west-2.amazonaws...      pdf   \n",
       "4  2019  english  https://ungc-production.s3.us-west-2.amazonaws...      pdf   \n",
       "\n",
       "                                        FileName  \n",
       "0                      0000-2019-agni-motors.pdf  \n",
       "1                        0001-2019-ambev-s-a.pdf  \n",
       "2  0002-2019-access-spectrum-company-limited.pdf  \n",
       "3                   0003-2019-addit-sp-z-o-o.pdf  \n",
       "4                       0004-2019-ahlsell-ab.pdf  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Participant</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Language</th>\n",
       "      <th>Link</th>\n",
       "      <th>FileType</th>\n",
       "      <th>FileName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNI MOTORS</td>\n",
       "      <td>Electronic &amp; Electrical Equ...</td>\n",
       "      <td>India</td>\n",
       "      <td>2019</td>\n",
       "      <td>english</td>\n",
       "      <td>https://ungc-production.s3.us-west-2.amazonaws...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0000-2019-agni-motors.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMBEV S/A</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2019</td>\n",
       "      <td>english</td>\n",
       "      <td>https://ungc-production.s3.us-west-2.amazonaws...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0001-2019-ambev-s-a.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Access Spectrum Company Limited</td>\n",
       "      <td>Technology Hardware &amp; Equip...</td>\n",
       "      <td>Myanmar</td>\n",
       "      <td>2019</td>\n",
       "      <td>english</td>\n",
       "      <td>https://ungc-production.s3.us-west-2.amazonaws...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0002-2019-access-spectrum-company-limited.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Addit Sp. z o.o.</td>\n",
       "      <td>General Industrials</td>\n",
       "      <td>Poland</td>\n",
       "      <td>2019</td>\n",
       "      <td>english</td>\n",
       "      <td>https://ungc-production.s3.us-west-2.amazonaws...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0003-2019-addit-sp-z-o-o.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ahlsell AB</td>\n",
       "      <td>Technology Hardware &amp; Equip...</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2019</td>\n",
       "      <td>english</td>\n",
       "      <td>https://ungc-production.s3.us-west-2.amazonaws...</td>\n",
       "      <td>pdf</td>\n",
       "      <td>0004-2019-ahlsell-ab.pdf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# download\n",
    "raw_path = \"../../data/raw-reports/\"\n",
    "if not os.path.exists(raw_path):\n",
    "    os.mkdir(raw_path)\n",
    "# func    \n",
    "def download_report(ind=0, df=docs, output_path=raw_path):\n",
    "    r = requests.get(df.loc[ind].Link, allow_redirects=True)\n",
    "    open(output_path+df.loc[ind].FileName, \"wb\").write(r.content)\n",
    "# par-all\n",
    "st = datetime.datetime.now()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=16) as exe: \n",
    "   exe.map(download_report,  docs.index) # docs.index\n",
    "td = (datetime.datetime.now()-st).seconds/60\n",
    "print(\"The download took {:.2f} mins on the threadpool back-end.\".format(td))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The download took 55.62 mins on the threadpool back-end.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# annotate files\n",
    "docs[\"FileTypeMagic\"] = docs.FileName.apply(lambda x: magic.from_file(raw_path+x,\n",
    "    mime=True))\n",
    "docs[\"FileTypeMagic\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "application/pdf                                                              2412\n",
       "application/vnd.openxmlformats-officedocument.wordprocessingml.document        34\n",
       "text/html                                                                       8\n",
       "application/vnd.openxmlformats-officedocument.presentationml.presentation       8\n",
       "application/msword                                                              2\n",
       "inode/x-empty                                                                   1\n",
       "application/octet-stream                                                        1\n",
       "Name: FileTypeMagic, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# prep\n",
    "text_path = \"../../data/text-reports/\"\n",
    "if not os.path.exists(text_path):\n",
    "    os.mkdir(text_path)\n",
    "\n",
    "docs[\"ConversionStatus\"] = np.nan\n",
    "docs[\"ConvertedFile\"] = np.nan\n",
    "# conversion\n",
    "st = datetime.datetime.now()\n",
    "\n",
    "for i in docs.index:\n",
    "\n",
    "    input_file = raw_path+docs.loc[i].FileName\n",
    "    temp_file = raw_path+docs.loc[i].FileName.split(\".\")[0]+\".pdf\"\n",
    "    output_file = text_path+docs.loc[i].FileName.split(\".\")[0]+\".txt\"\n",
    "\n",
    "    # check if conversion is needed\n",
    "    if (\"inode/x-empty\" not in docs.loc[i,\"FileTypeMagic\"]) &\\\n",
    "        (\"application/pdf\" not in docs.loc[i,\"FileTypeMagic\"]):\n",
    "        # and handle that\n",
    "        try:\n",
    "            cmd = \"unoconv -f pdf -T 30 -o \"+temp_file+\" \"+input_file\n",
    "            input_file = temp_file\n",
    "            docs.loc[i,\"ConversionStatus\"] = os.system(cmd)\n",
    "            os.system(\"pkill soffice.bin\")       \n",
    "        except:\n",
    "            print(\"Conversion of the file {} failed.\".format(input_file))\n",
    "            continue\n",
    "    # try to ocr the files\n",
    "    try:\n",
    "        cmd = \"./gs -sDEVICE=ocr -r200 -dQUIET -dBATCH -dNOPAUSE -sOutputFile=\"+\\\n",
    "            output_file+\" \"+input_file\n",
    "        docs.loc[i, \"ConversionStatus\"] = os.system(cmd)\n",
    "        with open(output_file, \"r\") as of:\n",
    "            docs.loc[i, \"OutputText\"] = of.read().replace(\"\\n\", \"\")\n",
    "    except:\n",
    "        print(\"OCR of the file {} failed.\".format(input_file))\n",
    "        continue\n",
    "    os.system(\"pkill gs\")\n",
    "\n",
    "td = (datetime.datetime.now()-st).seconds/60\n",
    "\n",
    "pdf_count = np.sum(docs.ConversionStatus==0)\n",
    "pdf_remainder_count = docs.shape[0]-pdf_count\n",
    "print(\"Type conversion finished in {} mins with {} pdf files and the remainder of {} raw files.\".\\\n",
    "    format(td, pdf_count, pdf_remainder_count,))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OCR of the file ../../data/raw-reports/0151-2020-3m-espa√±a-s-l.pdf failed.\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "docs.to_pickle(\"../../data/metadata_and_texts.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# text_path = \"../../data/text-reports-0/\"\n",
    "# if not os.path.exists(text_path):\n",
    "#    os.mkdir(text_path)#\n",
    "\n",
    "# def convert_to_text(ind=0, df=docs.dropna(), output_path=text_path):\n",
    "#    pdf_file = df.loc[ind].ConvertedFile\n",
    "#    text_file = output_path+df.loc[ind].FileName.split(\".\")[0]+\".txt\"\n",
    "#    imgs = pdf2image.convert_from_path(pdf_file, dpi=72)\n",
    "#    resulting_text = []\n",
    "#    for pg, img in enumerate(imgs):\n",
    "#        resulting_text.append(pytesseract.image_to_string(img))\n",
    "#    if os.path.exists(text_file):\n",
    "#        os.remove(text_file)\n",
    "#    open(text_file, \"w\").write(\" \".join(resulting_text))\n",
    "\n",
    "# st = datetime.datetime.now()\n",
    "# for i in docs.dropna().index:\n",
    "#    convert_to_text(ind=i, df=docs.dropna())\n",
    "# td = (datetime.datetime.now()-st).seconds/60\n",
    "# print(\"The ocr process took {:.2f} mins on the single thread back-end.\".format(td))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# text file to single "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9e6255f42a0ba260834f18bd8f97cae298885bfee9b81baa7cf63f030f508208"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}